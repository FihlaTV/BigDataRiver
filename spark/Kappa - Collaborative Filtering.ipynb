{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \\\n",
    "  '--conf spark.cassandra.connection.host=cassandra --packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.0.2,com.datastax.spark:spark-cassandra-connector_2.11:2.0.2 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"BigDataRiver\")\n",
    "sc.setLogLevel(\"WARN\")\n",
    "sc.setCheckpointDir('checkpoint/')\n",
    "ssc = StreamingContext(sc, 60)\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kafkaStream = KafkaUtils.createDirectStream(ssc, ['bdr'], {\"metadata.broker.list\": 'kafka:9092'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed = kafkaStream.map(lambda v: v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split is_purchase column into two\n",
    "separateClicksSchema = StructType([   \n",
    "    StructField(\"purchased_count\", LongType(), False),\n",
    "    StructField(\"clicked_count\", LongType(), False)\n",
    "])\n",
    "\n",
    "def separateClicks(is_purchase):\n",
    "  return (is_purchase, 1-is_purchase)\n",
    "\n",
    "separateClicks_udf = F.udf(separateClicks, separateClicksSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildCFModel(train):\n",
    "    def isProductToRating(productCount, clickCount):\n",
    "        return (productCount * 3.0) + clickCount\n",
    "    \n",
    "    ratings = train.rdd.\\\n",
    "        map(lambda r: Rating(r.user_id, r.product, isProductToRating(r.purchased_count, r.clicked_count)))\n",
    "    rank = 10\n",
    "    numIterations = 20\n",
    "    lambdaFactor = 0.01\n",
    "    alpha = 0.01\n",
    "    seed = 42\n",
    "    return ALS.trainImplicit(ratings, rank, numIterations, alpha, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommendTopProducts(dfModel):\n",
    "        numberOfRecommendationsRequired = 5\n",
    "        rdd = dfModel.recommendProductsForUsers(numberOfRecommendationsRequired)\n",
    "        recommendations = rdd.map(lambda (user,ratings): (user, map(lambda r: r.product, ratings)))\n",
    "        topRecommendationsSchema = StructType([\n",
    "            StructField(\"user_id\", IntegerType(), False),\n",
    "            StructField(\"recommended_products\", ArrayType(IntegerType()), False)\n",
    "        ])\n",
    "        return sql.createDataFrame(recommendations, topRecommendationsSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processStream(rdd):\n",
    "    df = sql.read.json(rdd)\n",
    "    if(len(df.columns)):\n",
    "        #store updated counters in C*\n",
    "        df.withColumn('c', separateClicks_udf(df['is_purchase'])).\\\n",
    "            select(\"user_id\",\"product\",\"c.purchased_count\",\"c.clicked_count\").\\\n",
    "            write.format(\"org.apache.spark.sql.cassandra\").mode('append').\\\n",
    "            options(table=\"users_interests\", keyspace=\"bdr\").save()\n",
    "            \n",
    "        #read all data from C*\n",
    "        usersInterests = sql.read.format(\"org.apache.spark.sql.cassandra\").\\\n",
    "            options(table=\"users_interests\", keyspace=\"bdr\").load().cache()\n",
    "\n",
    "        dfModel = buildCFModel(usersInterests.select(\"user_id\",\"product\",\"clicked_count\",\"purchased_count\"))\n",
    "        top5 = recommendTopProducts(dfModel)\n",
    "        top5.show()\n",
    "        top5.write.format(\"org.apache.spark.sql.cassandra\").mode('append').options(table=\"cf\", keyspace=\"bdr\").save()\n",
    "            \n",
    "        print \"Saved\"\n",
    "    else:\n",
    "        print \"Empty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed.foreachRDD(lambda rdd: processStream(rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|recommended_products|\n",
      "+-------+--------------------+\n",
      "|   1125| [9, 36, 29, 64, 67]|\n",
      "|   3800|  [9, 29, 36, 67, 5]|\n",
      "|   1825| [99, 29, 40, 6, 17]|\n",
      "|   5625|[46, 42, 18, 29, 64]|\n",
      "|   9626|[81, 78, 85, 55, 77]|\n",
      "|   3651|[78, 55, 40, 29, 17]|\n",
      "|   3751|  [82, 2, 99, 3, 62]|\n",
      "|   3802|[21, 95, 93, 37, 98]|\n",
      "|   1277|[42, 18, 91, 46, 50]|\n",
      "|   2002| [99, 29, 40, 6, 17]|\n",
      "|   4152|[95, 93, 21, 98, 37]|\n",
      "|   4752|[62, 93, 57, 95, 21]|\n",
      "|   1427|[11, 46, 68, 42, 18]|\n",
      "|   1903|[46, 42, 18, 29, 11]|\n",
      "|   3228| [5, 99, 36, 30, 37]|\n",
      "|   7528| [42, 18, 46, 5, 29]|\n",
      "|   3003|[62, 57, 11, 93, 46]|\n",
      "|   2403| [81, 78, 85, 62, 3]|\n",
      "|   5079| [37, 95, 21, 5, 98]|\n",
      "|   9979| [42, 18, 46, 91, 5]|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Saved\n",
      "+-------+--------------------+\n",
      "|user_id|recommended_products|\n",
      "+-------+--------------------+\n",
      "|   8125|  [91, 10, 48, 9, 2]|\n",
      "|   8500|  [9, 29, 36, 3, 64]|\n",
      "|   3975| [30, 5, 62, 37, 15]|\n",
      "|   1125|  [9, 3, 91, 21, 11]|\n",
      "|   9950| [5, 30, 37, 41, 18]|\n",
      "|   3800|  [64, 9, 29, 3, 36]|\n",
      "|    250|[99, 83, 50, 78, 37]|\n",
      "|   1825|[99, 29, 40, 17, 10]|\n",
      "|   8425|[37, 98, 99, 56, 55]|\n",
      "|   5625|[82, 46, 18, 41, 29]|\n",
      "|   6551|[29, 30, 10, 17, 55]|\n",
      "|   9626|[62, 57, 61, 85, 30]|\n",
      "|    251| [5, 18, 42, 50, 83]|\n",
      "|   3651|[55, 98, 56, 10, 37]|\n",
      "|   2401| [30, 29, 36, 5, 61]|\n",
      "|   4776|[18, 42, 41, 50, 46]|\n",
      "|   9976|[62, 82, 30, 59, 57]|\n",
      "|   9526| [99, 18, 50, 42, 5]|\n",
      "|   6226|[99, 78, 50, 83, 25]|\n",
      "|   3751| [82, 99, 2, 64, 62]|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
